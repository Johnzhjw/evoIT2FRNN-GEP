{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(filename='../dataset/_TS/gnfuv-pi2.csv'):\n",
    "    df = pd.read_csv(filename)\n",
    "    df_all = df\n",
    "    num_train = int(df.shape[0]*2/3)\n",
    "    df = df.iloc[0:num_train]\n",
    "    ###\n",
    "    cols = list(df)\n",
    "    df = df.loc[:, cols[0:2]]\n",
    "    df_all = df_all.loc[:, cols[0:2]]\n",
    "    #print(df)\n",
    "    date_ori = pd.to_datetime(df.iloc[:, 0]).tolist()\n",
    "    date_all_ori = pd.to_datetime(df_all.iloc[:, 0]).tolist()\n",
    "    #print(df.head())\n",
    "    df.head()\n",
    "    \n",
    "    return df, df_all, date_ori, date_all_ori, num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_norm(df, df_all):\n",
    "    allmean = [np.mean(df.iloc[:, i+1]).astype('float32') for i in range(df.shape[1]-1)]\n",
    "    allstd  = [np.std(df.iloc[:, i+1]).astype('float32') for i in range(df.shape[1]-1)]\n",
    "    #print(allmean)\n",
    "    #print(allstd)\n",
    "    #print(allmean[0])\n",
    "    #print(allstd[0])\n",
    "    df_log = [(df.iloc[:, i+1].astype('float32')-np.mean(df.iloc[:, i+1]).astype('float32'))/np.std(df.iloc[:, i+1]).astype('float32') for i in range(df.shape[1]-1)]\n",
    "    #minmax = MinMaxScaler().fit(df.iloc[:, 1:].astype('float32'))\n",
    "    #df_log = minmax.transform(df.iloc[:, 1:].astype('float32'))\n",
    "    df_log = pd.DataFrame(df_log)\n",
    "    df_log = pd.DataFrame(df_log.values.T, index=df_log.columns, columns=df_log.index)\n",
    "    #print(df_log.head())\n",
    "    #print(df_log.shape[0])\n",
    "    #print(df_log.iloc[0,0])\n",
    "    #\n",
    "    df_all_log = [(df_all.iloc[:, i+1].astype('float32')-np.mean(df.iloc[:, i+1]).astype('float32'))/np.std(df.iloc[:, i+1]).astype('float32') for i in range(df.shape[1]-1)]\n",
    "    #minmax = MinMaxScaler().fit(df.iloc[:, 1:].astype('float32'))\n",
    "    #df_log = minmax.transform(df.iloc[:, 1:].astype('float32'))\n",
    "    df_all_log = pd.DataFrame(df_all_log)\n",
    "    df_all_log = pd.DataFrame(df_all_log.values.T, index=df_all_log.columns, columns=df_all_log.index)\n",
    "    #print(df_all_log.head())\n",
    "    #print(df_all_log.shape[0])\n",
    "    #print(df_all_log.iloc[0,0])\n",
    "    \n",
    "    return df_log, df_all_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate,\n",
    "        num_layers,\n",
    "        size,\n",
    "        size_layer,\n",
    "        output_size,\n",
    "        forget_bias = 0.1,\n",
    "    ):\n",
    "        def lstm_cell(size_layer):\n",
    "            return tf.nn.rnn_cell.LSTMCell(size_layer, state_is_tuple = False)\n",
    "\n",
    "        rnn_cells = tf.nn.rnn_cell.MultiRNNCell(\n",
    "            [lstm_cell(size_layer) for _ in range(num_layers)],\n",
    "            state_is_tuple = False,\n",
    "        )\n",
    "        self.X = tf.placeholder(tf.float32, (None, None, size))\n",
    "        self.Y = tf.placeholder(tf.float32, (None, output_size))\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(\n",
    "            rnn_cells, output_keep_prob = forget_bias\n",
    "        )\n",
    "        self.hidden_layer = tf.placeholder(\n",
    "            tf.float32, (None, num_layers * 2 * size_layer)\n",
    "        )\n",
    "        self.outputs, self.last_state = tf.nn.dynamic_rnn(\n",
    "            drop, self.X, initial_state = self.hidden_layer, dtype = tf.float32\n",
    "        )\n",
    "        self.logits = tf.layers.dense(self.outputs[-1], output_size)\n",
    "        self.cost = tf.reduce_mean(tf.square(self.Y - self.logits))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(\n",
    "            self.cost\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init_paras(num_layers, df_log, size_layer, dropout_rate):\n",
    "    tf.reset_default_graph()\n",
    "    modelnn = Model(\n",
    "        0.01, num_layers, df_log.shape[1], size_layer, df_log.shape[1], dropout_rate\n",
    "    )\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    return modelnn, sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(epoch, num_layers, df_log, size_layer, timestamp):\n",
    "    for i in range(epoch):\n",
    "        init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
    "        total_loss = 0\n",
    "        for k in range(0, df_log.shape[0] - 1, timestamp):\n",
    "            index = min(k + timestamp, df_log.shape[0] -1)\n",
    "            batch_x = np.expand_dims(\n",
    "                df_log.iloc[k : index, :].values, axis = 0\n",
    "            )\n",
    "            batch_y = df_log.iloc[k + 1 : index + 1, :].values\n",
    "            last_state, _, loss = sess.run(\n",
    "                [modelnn.last_state, modelnn.optimizer, modelnn.cost],\n",
    "                feed_dict = {\n",
    "                    modelnn.X: batch_x,\n",
    "                    modelnn.Y: batch_y,\n",
    "                    modelnn.hidden_layer: init_value,\n",
    "                },\n",
    "            )\n",
    "            init_value = last_state\n",
    "            total_loss += loss\n",
    "        total_loss /= df_log.shape[0] // timestamp\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print('epoch:', i + 1, 'avg loss:', total_loss)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_predict(df_all_log, date_all_ori, future_day, timestamp, num_layers, size_layer):\n",
    "    df_log = df_all_log\n",
    "    date_ori = date_all_ori\n",
    "    #print(df_log.shape[0])\n",
    "    output_predict = np.zeros((df_log.shape[0] + future_day, df_log.shape[1]))\n",
    "    output_predict[0] = df_log.iloc[0]\n",
    "    #print(output_predict[0])\n",
    "    #print(output_predict.shape[0])\n",
    "    upper_b = ((df_log.shape[0] - 1) // timestamp) * timestamp\n",
    "    #print(upper_b)\n",
    "    init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
    "    for k in range(0, ((df_log.shape[0] - 1) // timestamp) * timestamp, timestamp):\n",
    "        out_logits, last_state = sess.run(\n",
    "            [modelnn.logits, modelnn.last_state],\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(\n",
    "                    df_log.iloc[k : k + timestamp], axis = 0\n",
    "                ),\n",
    "                modelnn.hidden_layer: init_value,\n",
    "            },\n",
    "        )\n",
    "        init_value = last_state\n",
    "        output_predict[k + 1 : k + timestamp + 1] = out_logits\n",
    "\n",
    "    out_logits, last_state = sess.run(\n",
    "        [modelnn.logits, modelnn.last_state],\n",
    "        feed_dict = {\n",
    "            modelnn.X: np.expand_dims(df_log.iloc[upper_b:], axis = 0),\n",
    "            modelnn.hidden_layer: init_value,\n",
    "        },\n",
    "    )\n",
    "    init_value = last_state\n",
    "    output_predict[upper_b + 1 : df_log.shape[0] + 1] = out_logits\n",
    "    df_log.loc[df_log.shape[0]] = out_logits[-1]\n",
    "    date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "    \n",
    "    return output_predict, upper_b, df_log, date_ori, init_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict_more(output_predict, upper_b, df_log, date_ori, init_value):\n",
    "    #print(output_predict[upper_b + 1 : df_log.shape[0] + 1])\n",
    "    for i in range(future_day - 1):\n",
    "        out_logits, last_state = sess.run(\n",
    "            [modelnn.logits, modelnn.last_state],\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(df_log.iloc[-timestamp:], axis = 0),\n",
    "                modelnn.hidden_layer: init_value,\n",
    "            },\n",
    "        )\n",
    "        init_value = last_state\n",
    "        output_predict[df_log.shape[0]] = out_logits[-1]\n",
    "        df_log.loc[df_log.shape[0]] = out_logits[-1]\n",
    "        date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "        \n",
    "    return df_log, date_ori, output_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm_data(df_log, date_ori, output_predict):\n",
    "    #print(df_log.iloc[-timestamp:])\n",
    "    df_log = [output_predict[:, i].astype('float32')*np.std(df.iloc[:, i+1]).astype('float32')+np.mean(df.iloc[:, i+1]).astype('float32') for i in range(df.shape[1]-1)]\n",
    "    df_log = pd.DataFrame(df_log)\n",
    "    df_log = pd.DataFrame(df_log.values.T, index=df_log.columns, columns=df_log.index)\n",
    "    df_log_norm = [output_predict[:, i].astype('float32') for i in range(df.shape[1]-1)]\n",
    "    df_log_norm = pd.DataFrame(df_log_norm)\n",
    "    df_log_norm = pd.DataFrame(df_log_norm.values.T, index=df_log_norm.columns, columns=df_log_norm.index)\n",
    "    #print(df_log)\n",
    "    #df_log = minmax.inverse_transform(output_predict)\n",
    "    date_ori = pd.Series(date_ori).dt.strftime(date_format = '%Y-%m-%d').tolist()\n",
    "    \n",
    "    return df_log, df_log_norm, date_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_data(df, df_all):\n",
    "    df_train = df\n",
    "    df = df_all\n",
    "    #print(df_log.shape[0])\n",
    "    return df_train, df\n",
    "\n",
    "def anchor(signal, weight):\n",
    "    buffer = []\n",
    "    last = signal[0]\n",
    "    for i in signal:\n",
    "        smoothed_val = last * weight + (1 - weight) * i\n",
    "        buffer.append(smoothed_val)\n",
    "        last = smoothed_val\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined(df, df_log):\n",
    "    numcols=len(list(df))\n",
    "    current_palette = sns.color_palette('Paired', 2*numcols)\n",
    "    fig = plt.figure(figsize = (15, 10))\n",
    "    ax = plt.subplot(111)\n",
    "    x_range_original = np.arange(df.shape[0])\n",
    "    x_range_future = np.arange(df_log.shape[0])\n",
    "    for ind in range(numcols-1):\n",
    "        ind2=ind+1\n",
    "        ax.plot(\n",
    "            x_range_original,\n",
    "            df.iloc[:, ind2],\n",
    "            label = 'true '+'%d'%ind2,\n",
    "            color = current_palette[ind*2],\n",
    "        )\n",
    "        ax.plot(\n",
    "            x_range_future,\n",
    "            anchor(df_log.iloc[:, ind], 0.5),\n",
    "            label = 'predict '+'%d'%ind,\n",
    "            color = current_palette[ind*2+1],\n",
    "        )\n",
    "    box = ax.get_position()\n",
    "    ax.set_position(\n",
    "        [box.x0, box.y0 + box.height * 0.1, box.width, box.height * 0.9]\n",
    "    )\n",
    "    ax.legend(\n",
    "        loc = 'upper center',\n",
    "        bbox_to_anchor = (0.5, -0.05),\n",
    "        fancybox = True,\n",
    "        shadow = True,\n",
    "        ncol = 5,\n",
    "    )\n",
    "    plt.title('overlap stock market')\n",
    "    #plt.xticks(x_range_future[::30], date_ori[::30])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_separated(df, df_log):\n",
    "    numcols=len(list(df))\n",
    "    current_palette = sns.color_palette('Paired', 2*numcols)\n",
    "    fig = plt.figure(figsize = (20, 8))\n",
    "    x_range_original = np.arange(df.shape[0])\n",
    "    x_range_future = np.arange(df_log.shape[0])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for ind in range(numcols-1):\n",
    "        ind2=ind+1\n",
    "        plt.plot(\n",
    "            x_range_original,\n",
    "            df.iloc[:, ind2],\n",
    "            label = 'true '+'%d'%ind2,\n",
    "            color = current_palette[ind*2],\n",
    "        )\n",
    "    #plt.xticks(x_range_original[::60], df.iloc[:, 0].tolist()[::60])\n",
    "    plt.legend()\n",
    "    plt.title('true market')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for ind in range(numcols-1):\n",
    "        plt.plot(\n",
    "            x_range_future,\n",
    "            anchor(df_log.iloc[:, ind], 0.5),\n",
    "            label = 'predict '+'%d'%ind,\n",
    "            color = current_palette[ind*2+1],\n",
    "        )\n",
    "    #plt.xticks(x_range_future[::60], date_ori[::60])\n",
    "    plt.legend()\n",
    "    plt.title('predict market')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateRMSE(X,Y): \n",
    "  return (np.linalg.norm(X-Y, ord=2)/len(Y))**0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_val_train(df_all_log, df_log, num_train):\n",
    "    if filename.find('gnfuv') >= 0:\n",
    "        df_true = pd.concat([df_all_log.iloc[0:num_train, 0]])\n",
    "        df_pred = pd.concat([df_log.iloc[0:num_train, 0]])\n",
    "    if filename.find('hungary') >= 0:\n",
    "        df_true = pd.concat([df_all_log.iloc[0:num_train, 0]])\n",
    "        df_pred = pd.concat([df_log.iloc[0:num_train, 0]])\n",
    "    if filename.find('NEW-DATA') >= 0:\n",
    "        df_true = pd.concat([df_all_log.iloc[0:num_train, 0]])\n",
    "        df_pred = pd.concat([df_log.iloc[0:num_train, 0]])\n",
    "    if filename.find('traffic') >= 0:\n",
    "        df_true = pd.concat([df_all_log.iloc[0:num_train, 0]])\n",
    "        df_pred = pd.concat([df_log.iloc[0:num_train, 0]])\n",
    "    if filename.find('Daily_Demand_Forecasting_Orders') >= 0:\n",
    "        df_true = pd.concat([df_all_log.iloc[0:num_train, 0]])\n",
    "        df_pred = pd.concat([df_log.iloc[0:num_train, 0]])\n",
    "    \n",
    "    tmp = calculateRMSE(df_true,df_pred)\n",
    "    \n",
    "    return tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_val_test(df_all_log, df_log, num_train):\n",
    "    num_all = df.shape[0]\n",
    "    if filename.find('gnfuv') >= 0:\n",
    "        df_true = pd.concat([df_all_log.iloc[num_train:num_all, 0]])\n",
    "        df_pred = pd.concat([df_log.iloc[num_train:num_all, 0]])\n",
    "    if filename.find('hungary') >= 0:\n",
    "        df_true = pd.concat([df_all_log.iloc[num_train:num_all, 0]])\n",
    "        df_pred = pd.concat([df_log.iloc[num_train:num_all, 0]])\n",
    "    if filename.find('NEW-DATA') >= 0:\n",
    "        df_true = pd.concat([df_all_log.iloc[num_train:num_all, 0]])\n",
    "        df_pred = pd.concat([df_log.iloc[num_train:num_all, 0]])\n",
    "    if filename.find('traffic') >= 0:\n",
    "        df_true = pd.concat([df_all_log.iloc[num_train:num_all, 0]])\n",
    "        df_pred = pd.concat([df_log.iloc[num_train:num_all, 0]])\n",
    "    if filename.find('Daily_Demand_Forecasting_Orders') >= 0:\n",
    "        df_true = pd.concat([df_all_log.iloc[num_train:num_all, 0]])\n",
    "        df_pred = pd.concat([df_log.iloc[num_train:num_all, 0]])\n",
    "    \n",
    "    tmp = calculateRMSE(df_true,df_pred)\n",
    "    \n",
    "    return tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_run = 10\n",
    "num_layers = 1\n",
    "size_layer = 10\n",
    "timestamp = 1\n",
    "epoch = 200\n",
    "dropout_rate = 0.7\n",
    "future_day = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='../dataset/_TS/NEW-DATA-1.T15.csv'\n",
    "\n",
    "all_error_train = []\n",
    "all_error_test  = []\n",
    "\n",
    "for _ in range(num_run):\n",
    "    df, df_all, date_ori, date_all_ori, num_train = get_stock_data(filename)\n",
    "    df_log, df_all_log = data_norm(df, df_all)\n",
    "    modelnn, sess = model_init_paras(num_layers, df_log, size_layer, dropout_rate)\n",
    "    model_train(epoch, num_layers, df_log, size_layer, timestamp)\n",
    "    output_predict, upper_b, df_log, date_ori, init_value = model_predict(df_all_log, date_all_ori, future_day, timestamp, num_layers, size_layer)\n",
    "    df_log, date_ori, output_predict = model_predict_more(output_predict, upper_b, df_log, date_ori, init_value)\n",
    "    df_log, df_log_norm, date_ori = denorm_data(df_log, date_ori, output_predict)\n",
    "    df_train, df = swap_data(df, df_all)\n",
    "    plot_combined(df, df_log)\n",
    "    plot_separated(df, df_log)\n",
    "    error_train = get_error_val_train(df_all_log, df_log_norm, num_train)\n",
    "    error_test = get_error_val_test(df_all_log, df_log_norm, num_train)\n",
    "    if _ == 0:\n",
    "        all_error_train = error_train\n",
    "        all_error_test  = error_test\n",
    "    else:\n",
    "        all_error_train = np.vstack((all_error_train,error_train))\n",
    "        all_error_test  = np.vstack((all_error_test,error_test))\n",
    "    sess.close()\n",
    "\n",
    "print('all train')\n",
    "print(all_error_train)\n",
    "print('all test')\n",
    "print(all_error_test)\n",
    "print('mean train')\n",
    "print(np.mean(all_error_train, axis=0))\n",
    "print('mean test')\n",
    "print(np.mean(all_error_test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('all train')\n",
    "print(all_error_train)\n",
    "print('all test')\n",
    "print(all_error_test)\n",
    "print('mean train')\n",
    "print(np.mean(all_error_train, axis=0))\n",
    "print('mean test')\n",
    "print(np.mean(all_error_test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='../dataset/_TS/NEW-DATA-2.T15.csv'\n",
    "\n",
    "all_error_train = []\n",
    "all_error_test  = []\n",
    "\n",
    "for _ in range(num_run):\n",
    "    df, df_all, date_ori, date_all_ori, num_train = get_stock_data(filename)\n",
    "    df_log, df_all_log = data_norm(df, df_all)\n",
    "    modelnn, sess = model_init_paras(num_layers, df_log, size_layer, dropout_rate)\n",
    "    model_train(epoch, num_layers, df_log, size_layer, timestamp)\n",
    "    output_predict, upper_b, df_log, date_ori, init_value = model_predict(df_all_log, date_all_ori, future_day, timestamp, num_layers, size_layer)\n",
    "    df_log, date_ori, output_predict = model_predict_more(output_predict, upper_b, df_log, date_ori, init_value)\n",
    "    df_log, df_log_norm, date_ori = denorm_data(df_log, date_ori, output_predict)\n",
    "    df_train, df = swap_data(df, df_all)\n",
    "    plot_combined(df, df_log)\n",
    "    plot_separated(df, df_log)\n",
    "    error_train = get_error_val_train(df_all_log, df_log_norm, num_train)\n",
    "    error_test = get_error_val_test(df_all_log, df_log_norm, num_train)\n",
    "    if _ == 0:\n",
    "        all_error_train = error_train\n",
    "        all_error_test  = error_test\n",
    "    else:\n",
    "        all_error_train = np.vstack((all_error_train,error_train))\n",
    "        all_error_test  = np.vstack((all_error_test,error_test))\n",
    "    sess.close()\n",
    "\n",
    "print('all train')\n",
    "print(all_error_train)\n",
    "print('all test')\n",
    "print(all_error_test)\n",
    "print('mean train')\n",
    "print(np.mean(all_error_train, axis=0))\n",
    "print('mean test')\n",
    "print(np.mean(all_error_test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('all train')\n",
    "print(all_error_train)\n",
    "print('all test')\n",
    "print(all_error_test)\n",
    "print('mean train')\n",
    "print(np.mean(all_error_train, axis=0))\n",
    "print('mean test')\n",
    "print(np.mean(all_error_test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
